{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1_t4V9bnt-hB",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36d84e010817fee9ca731581dcbc354a",
     "grade": false,
     "grade_id": "cell-e911fa75d4ae6ea9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "# Assignment 2: Hyperparameter Optimizartion For The Human Freedom Index Model\n",
    "\n",
    "This notebook contains a set of exercises that will guide you through the different steps of this assignment. As in Assignment 1, solutions need to be code-based, _i.e._ hard-coded or manually computed results will not be accepted. Remember to write your solutions to each exercise in the dedicated cells and to not modify the test cells. When you are done completing all the exercises submit this same notebook back to moodle in **.ipynb** format.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "The <a href=\"https://www.cato.org/human-freedom-index/2021 \">Human Freedom Index</a> measures economic freedoms such as the freedom to trade or to use sound money, and it captures the degree to which people are free to enjoy the major freedoms often referred to as civil liberties—freedom of speech, religion, association, and assembly— in the countries in the survey. In addition, it includes indicators on rule of law, crime and violence, freedom of movement, and legal discrimination against same-sex relationships. We also include nine variables pertaining to women-specific freedoms that are found in various categories of the index.\n",
    "\n",
    "<u>Citation</u>\n",
    "\n",
    "Ian Vásquez, Fred McMahon, Ryan Murphy, and Guillermina Sutter Schneider, The Human Freedom Index 2021: A Global Measurement of Personal, Civil, and Economic Freedom (Washington: Cato Institute and the Fraser Institute, 2021).\n",
    "    \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\"><b>Submission deadline:</b> Sunday, February 12th, 23:55</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0f1f0289d715c8a9dce469c89a4174b",
     "grade": false,
     "grade_id": "cell-0d9a7d4e70c072c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "JdETeU66gS1E",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cbd36cda059448e32e30917ff68670ee",
     "grade": false,
     "grade_id": "cell-8f995c9cdf882820",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 1</b>\n",
    "    \n",
    "Load the Human Freedom Index data from the link: https://github.com/jnin/information-systems/raw/main/data/hfi_cc_2021.csv in a DataFrame called ```df```. The following columns are redundant and should be dropped:\n",
    "* ```year```\n",
    "* ```ISO```\n",
    "* ```countries```\n",
    "* All columns containing the word ```rank``` \n",
    "* All columns containing the word ```score```\n",
    "\n",
    "Then store the independent variables in a DataFrame called ```X``` and the dependent variable (```hf_quartile```) in a DataFrame called ```y```.\n",
    "    \n",
    "<br><i>[0.5 points]</i>\n",
    "</div>\n",
    "<div class=\"alert alert-warning\">\n",
    "Do not download the dataset. Instead, read the data directly from the provided link\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3416f03882927817c5373de161fb4a59",
     "grade": false,
     "grade_id": "ex1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/jnin/information-systems/raw/main/data/hfi_cc_2021.csv')\n",
    "\n",
    "# remove target values with missing values\n",
    "df = df.dropna(subset=['hf_quartile'])\n",
    "\n",
    "# remove columns that are specified to be redundant\n",
    "df = df.drop(columns = ['year', 'ISO', 'countries'])\n",
    "\n",
    "# drop columns that contain the word rank or score  \n",
    "df = df.filter(regex='^(?!.*score.*|.*rank.*)')\n",
    "\n",
    "# Seperate target variable and the features \n",
    "X = df.drop(columns = [\"hf_quartile\"])\n",
    "y = df[\"hf_quartile\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "I4Ai5L-bgQI-",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9bc13605b63554dd684e5c3359109498",
     "grade": false,
     "grade_id": "cell-cac60b3d5a84bc9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 2</b>\n",
    "    \n",
    "Write the code to create a ```Pipeline``` consisting of a ```SimpleImputer``` with the most frequent strategy, a ```OneHotEncoder``` for the categorical variables, a standard scaler, and a logistic regression model with the solver ```saga``` and ```max_iter```2000. Store the resulting pipeline in a variable called ```pipe```.\n",
    "    \n",
    "<br><i>[1 point]</i>\n",
    "</div>\n",
    "<div class='alert alert-warning'>\n",
    "\n",
    "Not all the attributes are categorical. Ensure that all non-categorical attributes remain intact.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the categorical feature\n",
    "categorical_features = X.select_dtypes(include='object').columns\n",
    "\n",
    "# Build a transformer to deal with categorical variables in the steps \n",
    "transformer = ColumnTransformer([('ohe', OneHotEncoder(sparse=False), [0])], remainder='passthrough')\n",
    "\n",
    "\n",
    "# Create a pipeline using saga and max iterations of 2000\n",
    "steps = [('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "          ('transformer', transformer),\n",
    "          ('scaler', StandardScaler()),\n",
    "          ('classifier', LogisticRegression(solver='saga', max_iter=2000))]\n",
    "\n",
    "pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "I4Ai5L-bgQI-",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd5fab28e05b69b65eb89f8d17a57943",
     "grade": false,
     "grade_id": "cell-cac60b3d5a84bcasdfa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 3</b>\n",
    "\n",
    "Write the code to estimate the performance of the model using cross-validation with **three** stratified folds. Store the three test score values in a dictionary called ```fold_scores```.\n",
    "    \n",
    "<br><i>[1 point]</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "id": "2EZ4PgrhYpcn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69b315830f2239f6d81c0964227610ff",
     "grade": false,
     "grade_id": "ex3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold1': 0.9181380417335474,\n",
       " 'fold2': 0.9501607717041801,\n",
       " 'fold3': 0.8954983922829582}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_fold_scores = cross_val_score(pipe, X, y, cv = StratifiedKFold(n_splits=3))\n",
    "fold_scores = {'fold1' : single_fold_scores[0],\n",
    "               'fold2' : single_fold_scores[1],\n",
    "               'fold3' : single_fold_scores[2]}\n",
    "fold_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "I4Ai5L-bgQI-",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfdf6a55bc7ea4dc37bddbc8066c40ff",
     "grade": false,
     "grade_id": "cell-cac60b3d5artw84bcasdfa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 4</b>\n",
    "\n",
    "    \n",
    "Write the code to create a GridSearchCV object called ```grid``` and fit it using **only three folds**. The grid search object must include the previous pipeline and test the following hyperparameters:\n",
    "* ```penalty``` : ['l1', 'l2']\n",
    "* ```C``` : [0.1,10]\n",
    "\n",
    "Finally, store the best achieved score (accuracy) in a variable called ```score```.\n",
    "\n",
    "<br><i>[2.5 points]</i>\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "\n",
    "Use train and test datasets correctly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00ef2091bcd0c6ccc4ed66e901f1fff9",
     "grade": false,
     "grade_id": "ex4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9438502673796791"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state= 7)\n",
    "\n",
    "# specify parameters to vary \n",
    "param_grid = {'classifier__penalty':['l1', 'l2'],\n",
    "               'classifier__C':[0.1, 10]}\n",
    "\n",
    "# perform grid search \n",
    "grid = GridSearchCV(pipe, param_grid, cv = 3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "score = grid.best_estimator_.score(X_test, y_test)\n",
    "score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "I4Ai5L-bgQI-",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f18076388ac95878aba1a2591b3953d",
     "grade": false,
     "grade_id": "cell-cac60b3d5artw84ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 5</b>\n",
    "    \n",
    "The previous grid search is incomplete because it only optimizes the hyperparameters of the logistic regression model. Now repeat the same process but testing parameters of all the steps of the pipeline. This exercise is open. You can use any hyperparameter from the scaler, imputer, transformer, encoder, or model. Do not limit yourself to linear models.\n",
    "\n",
    "<br><i>[5 points]</i>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Approach\n",
    "We will be checking the performance of each hyperparameter individually and evaluate the impact of each hyperparameter comparing to performance without tuning. We then will select the top 3 hyperparameters with the most impact on model performance to try out different combinations of these 3 hyperparemeters. At the end, we will choose the combination with the best performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to define a function for the approach \n",
    "\n",
    "def best_hype(params,pipe): \n",
    "    \n",
    "    #set empty dictionary that records hyperparameters that helped improve the performance\n",
    "    improve = {}\n",
    "    \n",
    "    #get the inital accuracy score without hyperparameter tuning\n",
    "    score_inital = np.mean(cross_val_score(pipe, X, y, cv=3))\n",
    "    print(score_inital, \" Accuracy without tuning\")\n",
    "    \n",
    "    \n",
    "    #evaluate the performance of hyperparameters in isolation \n",
    "    scores = {}\n",
    "    for key,values in params.items():\n",
    "        single_param_grid = {key: values}\n",
    "        grid = GridSearchCV(pipe, single_param_grid, cv=3, n_jobs = -2)\n",
    "        grid.fit(X_train, y_train)\n",
    "        score = grid.best_estimator_.score(X_test, y_test)\n",
    "        scores[key] = score\n",
    "        print(f\" {score} : {key}, {grid.best_params_}\")\n",
    "    \n",
    "    #sort the scores to get the top three hyperparameters\n",
    "    top_three = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True)[:3])\n",
    "    \n",
    "    #trigger a combined search of top three parameters\n",
    "    print('\\n', \"We will evaluate the top three parameters: \")\n",
    "    for key, value in top_three.items():\n",
    "        print(f\"{key}: {params[key]}\")\n",
    "            \n",
    "    new_grid = GridSearchCV(pipe, {k: params[k] for k in top_three.keys()}, cv = 3, n_jobs = -2)\n",
    "    new_grid.fit(X_train, y_train)\n",
    "    best = new_grid.best_estimator_.score(X_test, y_test)\n",
    "    print('\\n',best, \"Best combination: \", new_grid.best_params_)\n",
    "    \n",
    "    #get the best overall score from this evaluation (inital score, indivisual scores or combination of parameters)\n",
    "    best_score = max(score_inital, max(scores.values()), best)\n",
    "    print('\\n',best_score, \"Best overall score achieved \")\n",
    "    return best_score\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct a pipe for decision tree model \n",
    "pipe1 = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('transformer', transformer),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to test\n",
    "\n",
    "dt_grid = {\n",
    "    'classifier__criterion': ['gini', 'entropy'],\n",
    "    'classifier__splitter': ['best', 'random'],\n",
    "    'classifier__max_depth': [200, 300, 500, None],\n",
    "    'classifier__min_samples_split': [2, 3, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2, 3],\n",
    "    'classifier__max_leaf_nodes': [200, 300, 500, None],\n",
    "    'classifier__min_impurity_decrease': [0.0, 0.05, 0.1],\n",
    "    'classifier__ccp_alpha': [0.0, 0.05, 0.1],   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8564555559569831  Accuracy without tuning\n",
      " 0.8850267379679144 : classifier__criterion, {'classifier__criterion': 'entropy'}\n",
      " 0.9064171122994652 : classifier__splitter, {'classifier__splitter': 'best'}\n",
      " 0.9064171122994652 : classifier__max_depth, {'classifier__max_depth': None}\n",
      " 0.893048128342246 : classifier__min_samples_split, {'classifier__min_samples_split': 3}\n",
      " 0.9010695187165776 : classifier__min_samples_leaf, {'classifier__min_samples_leaf': 1}\n",
      " 0.9144385026737968 : classifier__max_leaf_nodes, {'classifier__max_leaf_nodes': None}\n",
      " 0.9144385026737968 : classifier__min_impurity_decrease, {'classifier__min_impurity_decrease': 0.0}\n",
      " 0.9037433155080213 : classifier__ccp_alpha, {'classifier__ccp_alpha': 0.0}\n",
      "\n",
      " We will evaluate the top three parameters: \n",
      "classifier__max_leaf_nodes: [200, 300, 500, None]\n",
      "classifier__min_impurity_decrease: [0.0, 0.05, 0.1]\n",
      "classifier__splitter: ['best', 'random']\n",
      "\n",
      " 0.8877005347593583 Best combination:  {'classifier__max_leaf_nodes': 500, 'classifier__min_impurity_decrease': 0.0, 'classifier__splitter': 'best'}\n",
      "\n",
      " 0.9144385026737968 Best overall score achieved \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate performance\n",
    "score1 = best_hype(dt_grid, pipe1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the pipe for RF\n",
    "\n",
    "pipe2 = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('transformer', transformer),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100))\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to test\n",
    "\n",
    "rf_grid = {\n",
    "    'imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "    'classifier__n_estimators': [10, 50, 100, 200, 500, 1000, 1500],\n",
    "    'classifier__max_depth': [5, 10, 15, 20, 25, 30, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10, 20, 30],\n",
    "    'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'classifier__criterion': ['gini', 'entropy'],\n",
    "    'classifier__bootstrap': [True, False],\n",
    "    'classifier__oob_score': [True, False],\n",
    "    'classifier__warm_start': [True, False],\n",
    "    'classifier__ccp_alpha': [0.0, 0.1, 0.5, 1.0],\n",
    "    'classifier__max_leaf_nodes': [None, 5, 10, 20, 50]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9196580181984279  Accuracy without tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "6 fits failed out of a total of 9.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py\", line 319, in fit\n",
      "    X = self._validate_input(X, in_fit=True)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py\", line 285, in _validate_input\n",
      "    raise new_ve from None\n",
      "ValueError: Cannot use mean strategy with non-numeric data:\n",
      "could not convert string to float: 'Eastern Europe'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py\", line 319, in fit\n",
      "    X = self._validate_input(X, in_fit=True)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py\", line 285, in _validate_input\n",
      "    raise new_ve from None\n",
      "ValueError: Cannot use median strategy with non-numeric data:\n",
      "could not convert string to float: 'Eastern Europe'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.93503457]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9411764705882353 : imputer__strategy, {'imputer__strategy': 'most_frequent'}\n",
      " 0.9491978609625669 : classifier__n_estimators, {'classifier__n_estimators': 500}\n",
      " 0.9438502673796791 : classifier__max_depth, {'classifier__max_depth': 25}\n",
      " 0.9518716577540107 : classifier__min_samples_split, {'classifier__min_samples_split': 5}\n",
      " 0.9385026737967914 : classifier__min_samples_leaf, {'classifier__min_samples_leaf': 1}\n",
      " 0.9545454545454546 : classifier__max_features, {'classifier__max_features': 'sqrt'}\n",
      " 0.9545454545454546 : classifier__criterion, {'classifier__criterion': 'gini'}\n",
      " 0.9491978609625669 : classifier__bootstrap, {'classifier__bootstrap': False}\n",
      " 0.9438502673796791 : classifier__oob_score, {'classifier__oob_score': True}\n",
      " 0.9438502673796791 : classifier__warm_start, {'classifier__warm_start': True}\n",
      " 0.946524064171123 : classifier__ccp_alpha, {'classifier__ccp_alpha': 0.0}\n",
      " 0.9411764705882353 : classifier__max_leaf_nodes, {'classifier__max_leaf_nodes': None}\n",
      "\n",
      " We will evaluate the top three parameters: \n",
      "classifier__max_features: ['auto', 'sqrt', 'log2', None]\n",
      "classifier__criterion: ['gini', 'entropy']\n",
      "classifier__min_samples_split: [2, 5, 10, 20, 30]\n",
      "\n",
      " 0.9518716577540107 Best combination:  {'classifier__criterion': 'entropy', 'classifier__max_features': 'auto', 'classifier__min_samples_split': 2}\n",
      "\n",
      " 0.9545454545454546 Best overall score achieved \n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "score2 = best_hype(rf_grid, pipe2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_grid = {\n",
    "    'imputer__strategy': ['most_frequent', 'mean', 'median'],\n",
    "    'scaler__with_mean': [True, False],\n",
    "    'scaler__with_std': [True, False],\n",
    "    'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'classifier__solver': ['saga', 'liblinear'],\n",
    "    'classifier__class_weight': [None, 'balanced'],\n",
    "    'classifier__fit_intercept': [True, False],\n",
    "    'classifier__C': [0.1, 1, 5, 10, 100],\n",
    "    'classifier__max_iter': [1000, 2000, 5000],\n",
    "    'classifier__multi_class': ['ovr', 'multinomial'],\n",
    "    'classifier__tol': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    'classifier__l1_ratio': [0, 0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'classifier__warm_start': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9212657352402287  Accuracy without tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "6 fits failed out of a total of 9.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py\", line 319, in fit\n",
      "    X = self._validate_input(X, in_fit=True)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py\", line 285, in _validate_input\n",
      "    raise new_ve from None\n",
      "ValueError: Cannot use mean strategy with non-numeric data:\n",
      "could not convert string to float: 'Eastern Europe'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py\", line 319, in fit\n",
      "    X = self._validate_input(X, in_fit=True)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py\", line 285, in _validate_input\n",
      "    raise new_ve from None\n",
      "ValueError: Cannot use median strategy with non-numeric data:\n",
      "could not convert string to float: 'Eastern Europe'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.93436657        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9598930481283422 : imputer__strategy, {'imputer__strategy': 'most_frequent'}\n",
      " 0.9598930481283422 : scaler__with_mean, {'scaler__with_mean': True}\n",
      " 0.9598930481283422 : scaler__with_std, {'scaler__with_std': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "3 fits failed out of a total of 9.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.93302923 0.93436657        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9598930481283422 : classifier__penalty, {'classifier__penalty': 'l2'}\n",
      " 0.9598930481283422 : classifier__solver, {'classifier__solver': 'saga'}\n",
      " 0.9598930481283422 : classifier__class_weight, {'classifier__class_weight': 'balanced'}\n",
      " 0.9598930481283422 : classifier__fit_intercept, {'classifier__fit_intercept': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9598930481283422 : classifier__C, {'classifier__C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9598930481283422 : classifier__max_iter, {'classifier__max_iter': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9598930481283422 : classifier__multi_class, {'classifier__multi_class': 'multinomial'}\n",
      " 0.9598930481283422 : classifier__tol, {'classifier__tol': 0.0001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9598930481283422 : classifier__l1_ratio, {'classifier__l1_ratio': 0}\n",
      " 0.9598930481283422 : classifier__warm_start, {'classifier__warm_start': True}\n",
      "\n",
      " We will evaluate the top three parameters: \n",
      "imputer__strategy: ['most_frequent', 'mean', 'median']\n",
      "scaler__with_mean: [True, False]\n",
      "scaler__with_std: [True, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "24 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py\", line 319, in fit\n",
      "    X = self._validate_input(X, in_fit=True)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py\", line 285, in _validate_input\n",
      "    raise new_ve from None\n",
      "ValueError: Cannot use mean strategy with non-numeric data:\n",
      "could not convert string to float: 'Eastern Europe'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py\", line 319, in fit\n",
      "    X = self._validate_input(X, in_fit=True)\n",
      "  File \"/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py\", line 285, in _validate_input\n",
      "    raise new_ve from None\n",
      "ValueError: Cannot use median strategy with non-numeric data:\n",
      "could not convert string to float: 'Eastern Europe'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/wakeupjz/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.93436657 0.92431833 0.90758608 0.90088456        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.9598930481283422 Best combination:  {'imputer__strategy': 'most_frequent', 'scaler__with_mean': True, 'scaler__with_std': True}\n",
      "\n",
      " 0.9598930481283422 Best overall score achieved \n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "score3 = best_hype(log_grid, pipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.914439</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.959893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Decision Tree  Random Forest  Logistic Regression\n",
       "Accuracy       0.914439       0.954545             0.959893"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview = pd.DataFrame({\"Decision Tree\": score1,\n",
    "                         \"Random Forest\": score2,\n",
    "                         \"Logistic Regression\": score3\n",
    "                          }, index = [\"Accuracy\"])\n",
    "\n",
    "overview"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Session I.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
