{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1_t4V9bnt-hB",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50fbc8263e8f31674a9919dc666a7a1b",
     "grade": false,
     "grade_id": "cell-e911fa75d4ae6ea9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "# Assignment 1: Predicting overall The Human Freedom Index\n",
    "\n",
    "This notebook contains a set of exercises that will guide you through the different steps of this assignment. Solutions need to be code-based, _i.e._ hard-coded or manually computed results will not be accepted. Remember to write your solutions to each exercise in the dedicated cells and to not modify the test cells. When you are done completing all the exercises submit this same notebook back to moodle in **.ipynb** format.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "The <a href=\"https://www.cato.org/human-freedom-index/2021 \">Human Freedom Index</a> measures economic freedoms such as the freedom to trade or to use sound money, and it captures the degree to which people are free to enjoy the major freedoms often referred to as civil liberties—freedom of speech, religion, association, and assembly— in the countries in the survey. In addition, it includes indicators on rule of law, crime and violence, freedom of movement, and legal discrimination against same-sex relationships. We also include nine variables pertaining to women-specific freedoms that are found in various categories of the index.\n",
    "\n",
    "<u>Citation</u>\n",
    "\n",
    "Ian Vásquez, Fred McMahon, Ryan Murphy, and Guillermina Sutter Schneider, The Human Freedom Index 2021: A Global Measurement of Personal, Civil, and Economic Freedom (Washington: Cato Institute and the Fraser Institute, 2021).\n",
    "    \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\"><b>Submission deadline:</b> Sunday, January 29th, 23:55</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1gbj1gyT16vl",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73165086c3e0ea8e4c4050187971bd5e",
     "grade": false,
     "grade_id": "cell-0fcbc57512e78927",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "JdETeU66gS1E",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "037ddc9204ef8e30636e4a2ebf41f852",
     "grade": false,
     "grade_id": "cell-8f995c9cdf882820",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 1</b>\n",
    "\n",
    "Load the Human Freedom Index data from the link: https://github.com/jnin/information-systems/raw/main/data/hfi_cc_2021.csv in a DataFrame called ```df```.\n",
    "\n",
    "<br><i>[0.25 points]</i>\n",
    "</div>\n",
    "<div class=\"alert alert-warning\">\n",
    "Do not download the dataset. Instead, read the data directly from the provided link\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "id": "2EZ4PgrhYpcn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3416f03882927817c5373de161fb4a59",
     "grade": false,
     "grade_id": "ex1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/jnin/information-systems/raw/main/data/hfi_cc_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "I4Ai5L-bgQI-",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ca96a1e0c052c3752e7d169fb898ed3",
     "grade": false,
     "grade_id": "cell-cac60b3d5a84bc9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "<div class=\"alert alert-info\"><b>Exercise 2</b>\n",
    "\n",
    "First write the code to drop all the columns from the DataFrame ```df``` except ```['hf_quartile', 'ef_regulation',  'pf_expression', 'region']```, then drop all the rows from ```df``` containing missing values present in the selected columns.\n",
    "\n",
    "<br><i>[0.25 points]</i>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Remember, Python is case-sensitive. The resulting DataFrame ```df``` should contain only four columns.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter df to only have specified columns \n",
    "df = df[['region','hf_quartile','ef_regulation', 'pf_expression']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values and drp rows with missing values \n",
    "df.isna().sum() \n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "993b92c5f265ac6c55d3f4f81f079818",
     "grade": true,
     "grade_id": "test2_1",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Reset the index of columns \n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>hf_quartile</th>\n",
       "      <th>ef_regulation</th>\n",
       "      <th>pf_expression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eastern Europe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.70</td>\n",
       "      <td>6.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.84</td>\n",
       "      <td>5.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.97</td>\n",
       "      <td>6.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Latin America &amp; the Caribbean</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.99</td>\n",
       "      <td>8.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caucasus &amp; Central Asia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.82</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          region  hf_quartile  ef_regulation  pf_expression\n",
       "0                 Eastern Europe          2.0           7.70           6.91\n",
       "1     Middle East & North Africa          4.0           5.84           5.11\n",
       "2             Sub-Saharan Africa          4.0           5.97           6.51\n",
       "3  Latin America & the Caribbean          2.0           5.99           8.40\n",
       "4        Caucasus & Central Asia          1.0           7.82           7.88"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect df \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "evERSqB9MPid",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "809062917104bc877969d8b047444ff1",
     "grade": false,
     "grade_id": "cell-c7c37aaa2f33b369",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 3</b> \n",
    "    \n",
    "Write the code to create the feature matrix ```X``` (```ef_regulation```,  ```pf_expression```, and ```region```) and the target array ```y``` (```hf_quartile```), then split them into separate training and test sets with the relative size of 0.75 and 0.25. Store the training and tests feature matrix in variables called ```X_train``` and ```X_test```, and the training and test label arrays as ```y_train``` and ```y_test```.\n",
    "    \n",
    "<br><i>[1 point]</i>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "id": "rnxOTovpEqpu",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69b315830f2239f6d81c0964227610ff",
     "grade": false,
     "grade_id": "ex3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test train set split \n",
    "X = df.drop(columns = ['hf_quartile'])\n",
    "y = df['hf_quartile']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    X_train: (1400, 3)\n",
      "    X_test: (467, 3)\n",
      "    y_train: (1400,)\n",
      "    y_test: (467,)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Quick check on train/test distribution\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "    X_train: {X_train.shape}\n",
    "    X_test: {X_test.shape}\n",
    "    y_train: {y_train.shape}\n",
    "    y_test: {y_test.shape}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "evERSqB9MPid",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d0ed1b62e0021c85ec54b300514e03a",
     "grade": false,
     "grade_id": "cell-c7c37aaa2f33b36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 4 </b> \n",
    "\n",
    "    \n",
    "The resulting feature matrix contains a categorical variable. Write the code to create a ```ColumnTransformer``` to encode it using the one-hot encoding method. Store the transformer in a variable called ```transformer```. At this stage, you do not need to run it.\n",
    "\n",
    "<br><i>[1 points]</i>\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "\n",
    "Not all the attributes are categorical. Ensure that all non-categorical attributes remain intact.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer([('ohe', OneHotEncoder(sparse=False), [0])]\n",
    "                                , remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "evERSqB9MPid",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a3cdf9b3d150a148d5274132be6a8c3",
     "grade": false,
     "grade_id": "cell-c7c37a1aa2f33b36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 5 </b> \n",
    "\n",
    "Write the code to create a ```Pipeline``` consisting of a ```SimpleImputer``` with the most frequent strategy, the previous transformer, a standard scaler, and a logistic regression model. Store the resulting pipeline in a variable called ```pipe```.\n",
    "    \n",
    "<br><i>[1.5 points]</i>\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "\n",
    "Be sure you apply the data transformations in the correct order.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('Impute', SimpleImputer(strategy='most_frequent')),\n",
    "          ('preprocess', transformer),\n",
    "          ('scaler', StandardScaler()),\n",
    "          ('logreg', LogisticRegression())]\n",
    "           \n",
    "pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "evERSqB9MPid",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb719dff68f6fe54574bff8bafc24393",
     "grade": false,
     "grade_id": "cell-c7c37a1aa2fjk33b36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 6 </b> \n",
    "    \n",
    "Write the code to store the achieved ```score``` (accuracy) in a variable called ```score```. \n",
    "    \n",
    "<br><i>[1 point]</i>\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "\n",
    "Use train and test datasets correctly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5d70d0859a7e9513d16031567e1eb90",
     "grade": false,
     "grade_id": "ex6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7773019271948608"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "pipe.fit(X_train, y_train)\n",
    "score = pipe.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "evERSqB9MPid",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "31cda44ca5d916698cf6df997f4aaee4",
     "grade": false,
     "grade_id": "cell-c7c37a1aa2fjk33bhj36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><b>Exercise 7 </b> \n",
    "    \n",
    "The previous exercises were simple because they included only three columns. Now repeat the same process but using the complete dataset. This exercise is open. You can use any scaler, imputer, transformer, or encoder. The only requirement is to train a logistic regression. If you decide to drop a column, justify the reason. \n",
    "    \n",
    "<br><i>[5 points]</i>\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-warning'>\n",
    "    \n",
    "The following columns are redundant and should be dropped:\n",
    "* ```year```\n",
    "* ```ISO```\n",
    "* ```countries```\n",
    "* All columns containing the word ```rank``` \n",
    "* All columns containing the word ```score```\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df with the same dataset \n",
    "df2 = pd.read_csv('https://github.com/jnin/information-systems/raw/main/data/hfi_cc_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>countries</th>\n",
       "      <th>ISO</th>\n",
       "      <th>region</th>\n",
       "      <th>hf_score</th>\n",
       "      <th>hf_rank</th>\n",
       "      <th>hf_quartile</th>\n",
       "      <th>pf_rol_procedural</th>\n",
       "      <th>pf_rol_civil</th>\n",
       "      <th>pf_rol_criminal</th>\n",
       "      <th>...</th>\n",
       "      <th>ef_regulation_business_adm</th>\n",
       "      <th>ef_regulation_business_bureaucracy</th>\n",
       "      <th>ef_regulation_business_start</th>\n",
       "      <th>ef_regulation_business_bribes</th>\n",
       "      <th>ef_regulation_business_licensing</th>\n",
       "      <th>ef_regulation_business_compliance</th>\n",
       "      <th>ef_regulation_business</th>\n",
       "      <th>ef_regulation</th>\n",
       "      <th>ef_score</th>\n",
       "      <th>ef_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Eastern Europe</td>\n",
       "      <td>8.14</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.97</td>\n",
       "      <td>4.76</td>\n",
       "      <td>4.26</td>\n",
       "      <td>...</td>\n",
       "      <td>5.65</td>\n",
       "      <td>6.67</td>\n",
       "      <td>9.74</td>\n",
       "      <td>6.24</td>\n",
       "      <td>5.62</td>\n",
       "      <td>7.18</td>\n",
       "      <td>6.85</td>\n",
       "      <td>7.70</td>\n",
       "      <td>7.81</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "      <td>5.26</td>\n",
       "      <td>154.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.64</td>\n",
       "      <td>4.35</td>\n",
       "      <td>...</td>\n",
       "      <td>4.22</td>\n",
       "      <td>2.22</td>\n",
       "      <td>9.31</td>\n",
       "      <td>2.58</td>\n",
       "      <td>8.77</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.84</td>\n",
       "      <td>4.90</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>6.09</td>\n",
       "      <td>129.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.72</td>\n",
       "      <td>4.43</td>\n",
       "      <td>3.60</td>\n",
       "      <td>...</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.44</td>\n",
       "      <td>8.73</td>\n",
       "      <td>4.70</td>\n",
       "      <td>7.92</td>\n",
       "      <td>6.78</td>\n",
       "      <td>5.59</td>\n",
       "      <td>5.97</td>\n",
       "      <td>5.50</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>ARG</td>\n",
       "      <td>Latin America &amp; the Caribbean</td>\n",
       "      <td>7.38</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.83</td>\n",
       "      <td>5.94</td>\n",
       "      <td>4.35</td>\n",
       "      <td>...</td>\n",
       "      <td>2.71</td>\n",
       "      <td>5.78</td>\n",
       "      <td>9.58</td>\n",
       "      <td>6.53</td>\n",
       "      <td>5.73</td>\n",
       "      <td>6.51</td>\n",
       "      <td>6.14</td>\n",
       "      <td>5.99</td>\n",
       "      <td>5.50</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Caucasus &amp; Central Asia</td>\n",
       "      <td>8.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.17</td>\n",
       "      <td>5.56</td>\n",
       "      <td>9.86</td>\n",
       "      <td>6.96</td>\n",
       "      <td>9.30</td>\n",
       "      <td>7.04</td>\n",
       "      <td>7.32</td>\n",
       "      <td>7.82</td>\n",
       "      <td>8.03</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  countries  ISO                         region  hf_score  hf_rank  \\\n",
       "0  2019    Albania  ALB                 Eastern Europe      8.14     43.0   \n",
       "1  2019    Algeria  DZA     Middle East & North Africa      5.26    154.0   \n",
       "2  2019     Angola  AGO             Sub-Saharan Africa      6.09    129.0   \n",
       "3  2019  Argentina  ARG  Latin America & the Caribbean      7.38     74.0   \n",
       "4  2019    Armenia  ARM        Caucasus & Central Asia      8.20     40.0   \n",
       "\n",
       "   hf_quartile  pf_rol_procedural  pf_rol_civil  pf_rol_criminal  ...  \\\n",
       "0          2.0               5.97          4.76             4.26  ...   \n",
       "1          4.0               5.21          5.64             4.35  ...   \n",
       "2          4.0               2.72          4.43             3.60  ...   \n",
       "3          2.0               6.83          5.94             4.35  ...   \n",
       "4          1.0                NaN           NaN              NaN  ...   \n",
       "\n",
       "   ef_regulation_business_adm  ef_regulation_business_bureaucracy  \\\n",
       "0                        5.65                                6.67   \n",
       "1                        4.22                                2.22   \n",
       "2                        2.94                                2.44   \n",
       "3                        2.71                                5.78   \n",
       "4                        5.17                                5.56   \n",
       "\n",
       "   ef_regulation_business_start  ef_regulation_business_bribes  \\\n",
       "0                          9.74                           6.24   \n",
       "1                          9.31                           2.58   \n",
       "2                          8.73                           4.70   \n",
       "3                          9.58                           6.53   \n",
       "4                          9.86                           6.96   \n",
       "\n",
       "   ef_regulation_business_licensing  ef_regulation_business_compliance  \\\n",
       "0                              5.62                               7.18   \n",
       "1                              8.77                               7.03   \n",
       "2                              7.92                               6.78   \n",
       "3                              5.73                               6.51   \n",
       "4                              9.30                               7.04   \n",
       "\n",
       "   ef_regulation_business  ef_regulation  ef_score  ef_rank  \n",
       "0                    6.85           7.70      7.81     31.0  \n",
       "1                    5.69           5.84      4.90    162.0  \n",
       "2                    5.59           5.97      5.50    153.0  \n",
       "3                    6.14           5.99      5.50    153.0  \n",
       "4                    7.32           7.82      8.03     15.0  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect df2 \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1980 entries, 0 to 1979\n",
      "Columns: 125 entries, year to ef_rank\n",
      "dtypes: float64(119), int64(3), object(3)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#Check the shape and data types of df2 \n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "id": "rnxOTovpEqpu",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d63da504327f2eb69ca079359b186511",
     "grade": true,
     "grade_id": "ex7",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# remove the year, ISO, and countries column\n",
    "\n",
    "df2.drop(columns=['year','ISO', 'countries'], axis=1, inplace=True)\n",
    "\n",
    "# remove the columns with score and rank in the name \n",
    "# ~ means not \n",
    "df2 = df2.loc[:, ~df2.columns.str.contains(\"rank|score\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1980 entries, 0 to 1979\n",
      "Columns: 114 entries, region to ef_regulation\n",
      "dtypes: float64(113), object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Check the shape and data types of df2 \n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the target variable \n",
    "\n",
    "1.0 -> Human Freedom Index between 7.5-10.0 <br>\n",
    "2.0 -> Human Freedom Index between 5.0-7.5 <br>\n",
    "3.0 -> Human Freedom Index between 2.5-5.0 <br>\n",
    "4.0 -> Human Freedom Index between 0.0-2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pf_rol_procedural               0.858676\n",
       "pf_assembly_freedom             0.855454\n",
       "pf_assembly_freedom_house       0.847266\n",
       "pf_expression_media             0.840668\n",
       "pf_ss_disappearances_torture    0.817109\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for variables with high correlation to the target variable, also need to exclude region which is string\n",
    "numeric_columns = df2.select_dtypes(include=np.number).columns.tolist()\n",
    "target_corrs = abs(df2[numeric_columns].corrwith(df2[\"hf_quartile\"]).sort_values())\n",
    "target_corrs.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataframe to only include significantly correlated features corrs >= 0.7 \n",
    "df2 = df2.drop(columns=target_corrs[target_corrs < 0.7].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values in target value \n",
    "df2[\"hf_quartile\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Nas in target value then reset index \n",
    "df2.dropna(subset=[\"hf_quartile\"], inplace=True)\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Seperate the target variable from the rest of the data \n",
    "X = df2.drop(\"hf_quartile\", axis=1)\n",
    "y = df2[\"hf_quartile\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning \n",
    "\n",
    "Missing values in the target variable have been removed in the early step. \n",
    "\n",
    "Next, the features are inspected for missing features and their corresponding severity. To address this, we will remove the feature when there's over 25% NA and impute the missing values in the case of under 25% NA, which will be done in a later step using sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pf_rol_civil</th>\n",
       "      <td>636</td>\n",
       "      <td>0.340653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pf_rol_procedural</th>\n",
       "      <td>636</td>\n",
       "      <td>0.340653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pf_assembly_freedom_bti</th>\n",
       "      <td>483</td>\n",
       "      <td>0.258704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pf_expression_freedom_bti</th>\n",
       "      <td>483</td>\n",
       "      <td>0.258704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pf_assembly_civil</th>\n",
       "      <td>34</td>\n",
       "      <td>0.018211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Total   Percent\n",
       "pf_rol_civil                 636  0.340653\n",
       "pf_rol_procedural            636  0.340653\n",
       "pf_assembly_freedom_bti      483  0.258704\n",
       "pf_expression_freedom_bti    483  0.258704\n",
       "pf_assembly_civil             34  0.018211"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = pd.DataFrame({\"Total\": X.isna().sum(), \"Percent\": (X.isna().sum()) / len(X)})\n",
    "missing.sort_values(by=\"Percent\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns with more than 25% missing values\n",
    "X = X.drop(columns=missing[missing[\"Percent\"] > 0.25].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate categorical and numerical features, so later we can apply different imputing startegies on them \n",
    "categorical_features = X_train.select_dtypes(exclude=np.number).columns.tolist()\n",
    "numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For numerical features, we will use median to impute the missing values \n",
    "transformer_num_pipe = Pipeline([(\"Impute\", SimpleImputer(strategy=\"median\"))])\n",
    "\n",
    "#For categorical features, we will use the most frequent value to impute the missing values\n",
    "transformer_cat_pipe = Pipeline(\n",
    "    [\n",
    "        (\"Impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(sparse=False)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer(\n",
    "    [\n",
    "        (\"Numeric\", transformer_num_pipe, numerical_features),\n",
    "        (\"Categorical\", transformer_cat_pipe, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Create a pipeline with transformer and logistic regression\n",
    "lr_pipe = Pipeline(\n",
    "    [\n",
    "        (\"Preprocessing\", transformer),\n",
    "        (\"Scaler\", StandardScaler()),\n",
    "        (\"LR\", LogisticRegression(solver=\"liblinear\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8501070663811563"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model performance (accuracy)\n",
    "lr_pipe.fit(X_train, y_train)\n",
    "lr_acc = lr_pipe.score(X_test, y_test)\n",
    "lr_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8657142857142858"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how model performs with training data to evaluate overfitting\n",
    "lr_pipe.score(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Session I.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
